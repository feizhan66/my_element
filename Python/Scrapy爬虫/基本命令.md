# 创建项目
scrapy startproject xiaohuar [project_dir]

# cd 进入项目
cd project_dir

## 查看所有可用命令
scrapy -h

## 新建一个spider命令
scrapy genspider feizhan feizhan.me

## 获取当前项目spider列表
scrapy list

## 启动抓取
scrapy crawl xiaohuar

## 编辑(使用环境变量中的编辑器linux)
scrapy edit <spider>

## 获取(内容在控制台输出)
- 使用Scrapy下载程序下载给定的URL，并将内容写入标准输出
scrapy fetch <url>

## 视图(预览蜘蛛获取到的页面)
- 在浏览器中打开给定的URL，因为您的Scrapy蜘蛛会“看到”它。有时蜘蛛会看到不同于普通用户的页面，因此可以用来检查蜘蛛“看到”的内容并确认它是您所期望的。
scrapy view <ur>

## Shell
- 为给定的URL启动Scrapy shell（如果给定），如果没有给出URL，则为空。还支持UNIX样式的本地文件路径，相对于 ./或../前缀或绝对文件路径。有关详细信息，请参阅Scrapy shell。
```
scrapy shell <url> [options]
```
```
--spider=SPIDER：绕过蜘蛛自动检测并强制使用特定的蜘蛛
-c code：评估shell中的代码，打印结果并退出
--no-redirect：不要遵循HTTP 3xx重定向（默认是遵循它们）; 这只会影响您在命令行中作为参数传递的URL; 一旦进入shell，fetch(url)默认情况下仍会遵循HTTP重定向。
```

## 解析
scrapy parse <url> [options]

## 设置
scrapy settings [options]

## runspider
- 在python文件中运行自宝行的蜘蛛，而无需创建项目
scrapy runspider <spider_file.py>

## 版本 
scrapy version [-v]

scrapy version -v

## 基准测试
scrapy bench


















